{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27368,"status":"ok","timestamp":1701146877865,"user":{"displayName":"Sunghoon Jung","userId":"09908976028244403256"},"user_tz":-540},"id":"GH1wFSQYawhd","outputId":"e3b02513-0a74-4dab-e143-14c6907a4169"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["전체 여행 로그 데이터"],"metadata":{"id":"mkQFBeqg8F7A"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Colab Notebooks/Capstone Design 2023 2nd/DropoutNet/torch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f53eaUi01Zrt","executionInfo":{"status":"ok","timestamp":1701147196281,"user_tz":-540,"elapsed":6,"user":{"displayName":"Sunghoon Jung","userId":"09908976028244403256"}},"outputId":"0d43ab4e-e5e9-4441-fb47-7462c4e04ae4"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Capstone Design 2023 2nd/DropoutNet/torch\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AxbR3YvR1fBH","executionInfo":{"status":"ok","timestamp":1701147253578,"user_tz":-540,"elapsed":1070,"user":{"displayName":"Sunghoon Jung","userId":"09908976028244403256"}},"outputId":"a6639434-cac3-4b22-c449-930d98a07dce"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["data.py\t\t    model.py\t rating_matrix.ipynb  utils.py\n","main_travel_log.py  __pycache__  test_torch_model.py\n"]}]},{"cell_type":"code","source":["!python main_travel_log.py --data-dir ../Dataset/all_travel_log/ --checkpoint-path ../checkpoint/ --tb-log-path ../tb_log --model-device \"cuda\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rBAUYwNh8Eng","outputId":"ade1efc4-75e8-44ce-d9f1-ad53cf77291e","executionInfo":{"status":"ok","timestamp":1701151486776,"user_tz":-540,"elapsed":107932,"user":{"displayName":"Sunghoon Jung","userId":"09908976028244403256"}}},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["running: 2023-11-28-05:51:17_2.0\n","[main] loaded U:(11687, 200),V:(9717, 200) elapsed [0 s]\n","[main] standardized U,V elapsed [0 s]\n","[main] loaded user feature sparse matrix: (11687, 6) elapsed [0 s]\n","[main] read train triplets 63784 elapsed [0 s]\n","[utils] read eval_cold triplets (7416,) elapsed [0 s]\n","[utils] loaded eval_cold elapsed [0 s]\n","\tn_test_users:[5203]\n","\tn_test_items:[7416]\n","\tR_train_inf: no R_train_inf for cold\n","\tR_test_inf: shape=(5203, 7416) nnz=[7191]\n","[main] initialized numpy data elapsed [0 s]\n","[main] initialized eval_cold elapsed [0 s]\n","\tu_concat rank=206\n","\tv_concat rank=200\n","======================================================================\n","[MAIN EPOCH : 1]\n","======================================================================\n","ubatch:   0% 0/20000 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/Capstone Design 2023 2nd/DropoutNet/torch/model.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  Ucontent = torch.tensor(Ucontent, dtype=torch.float32)\n","/content/drive/MyDrive/Colab Notebooks/Capstone Design 2023 2nd/DropoutNet/torch/model.py:120: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  v_concat = torch.tensor(Vin, dtype=torch.float32)\n","updates=20k f=0.0047 f_tot=123.90: 100% 20000/20000 [00:52<00:00, 379.34it/s]\n","[main] 1 [20000]b [20000]tot f=123.90 best[1] elapsed [56 s]\n","\t\t\t@10    @20    @30    @40    @50    @60    @70    @80    @90    @100  \n","cold start\t0.4848 0.6145 0.6871 0.7382 0.7699 0.7942 0.8232 0.8372 0.8495 0.8563\n","updates=40k f=0.0087 f_tot=114.43: 100% 20000/20000 [00:51<00:00, 387.24it/s]\n","[main] 2 [20000]b [40000]tot f=114.43 best[2] elapsed [54 s]\n","\t\t\t@10    @20    @30    @40    @50    @60    @70    @80    @90    @100  \n","cold start\t0.5037 0.6354 0.7076 0.7626 0.7960 0.8159 0.8445 0.8574 0.8721 0.8785\n","updates=60k f=0.0056 f_tot=110.90: 100% 20000/20000 [00:50<00:00, 396.67it/s]\n","[main] 3 [20000]b [60000]tot f=110.90 best[3] elapsed [52 s]\n","\t\t\t@10    @20    @30    @40    @50    @60    @70    @80    @90    @100  \n","cold start\t0.5145 0.6482 0.7171 0.7675 0.8021 0.8270 0.8512 0.8649 0.8786 0.8838\n","updates=80k f=0.0040 f_tot=110.56: 100% 20000/20000 [00:49<00:00, 403.27it/s]\n","[main] 4 [20000]b [80000]tot f=110.56 best[4] elapsed [51 s]\n","\t\t\t@10    @20    @30    @40    @50    @60    @70    @80    @90    @100  \n","cold start\t0.5219 0.6449 0.7166 0.7722 0.8043 0.8255 0.8531 0.8694 0.8799 0.8866\n","updates=100k f=0.0030 f_tot=111.23: 100% 20000/20000 [00:49<00:00, 401.86it/s]\n","[main] 5 [20000]b [100000]tot f=111.23 best[5] elapsed [51 s]\n","\t\t\t@10    @20    @30    @40    @50    @60    @70    @80    @90    @100  \n","cold start\t0.5332 0.6542 0.7206 0.7778 0.8095 0.8277 0.8529 0.8686 0.8813 0.8869\n","updates=120k f=0.0140 f_tot=110.80: 100% 20000/20000 [00:49<00:00, 406.82it/s]\n","[main] 6 [20000]b [120000]tot f=110.80 best[6] elapsed [51 s]\n","\t\t\t@10    @20    @30    @40    @50    @60    @70    @80    @90    @100  \n","cold start\t0.5304 0.6627 0.7283 0.7804 0.8106 0.8285 0.8572 0.8727 0.8834 0.8899\n","updates=140k f=0.0023 f_tot=109.61: 100% 20000/20000 [00:51<00:00, 391.43it/s]\n","[main] 7 [20000]b [140000]tot f=109.61 best[7] elapsed [53 s]\n","\t\t\t@10    @20    @30    @40    @50    @60    @70    @80    @90    @100  \n","cold start\t0.5430 0.6692 0.7416 0.7921 0.8239 0.8423 0.8664 0.8809 0.8903 0.8963\n","updates=160k f=0.0040 f_tot=110.67: 100% 20000/20000 [00:50<00:00, 393.49it/s]\n","[main] 8 [20000]b [160000]tot f=110.67 best[7] elapsed [52 s]\n","\t\t\t@10    @20    @30    @40    @50    @60    @70    @80    @90    @100  \n","cold start\t0.5259 0.6552 0.7206 0.7765 0.8072 0.8270 0.8553 0.8695 0.8817 0.8889\n","updates=180k f=0.0048 f_tot=105.54: 100% 20000/20000 [00:50<00:00, 398.25it/s]\n","[main] 9 [20000]b [180000]tot f=105.54 best[9] elapsed [52 s]\n","\t\t\t@10    @20    @30    @40    @50    @60    @70    @80    @90    @100  \n","cold start\t0.5397 0.6707 0.7375 0.7974 0.8263 0.8461 0.8708 0.8846 0.8947 0.8990\n","updates=200k f=0.0018 f_tot=106.91: 100% 20000/20000 [00:50<00:00, 392.86it/s]\n","[main] 10 [20000]b [200000]tot f=106.91 best[9] elapsed [53 s]\n","\t\t\t@10    @20    @30    @40    @50    @60    @70    @80    @90    @100  \n","cold start\t0.5318 0.6636 0.7372 0.7904 0.8231 0.8464 0.8718 0.8863 0.8959 0.9021\n","======================================================================\n","[MAIN EPOCH : 2]\n","======================================================================\n","updates=220k f=0.0035 f_tot=107.28: 100% 20000/20000 [00:51<00:00, 389.35it/s]\n","[main] 11 [20000]b [220000]tot f=107.28 best[11] elapsed [53 s]\n","\t\t\t@10    @20    @30    @40    @50    @60    @70    @80    @90    @100  \n","cold start\t0.5445 0.6707 0.7375 0.7969 0.8262 0.8473 0.8727 0.8856 0.8950 0.9020\n","updates=240k f=0.0100 f_tot=109.48: 100% 20000/20000 [00:50<00:00, 399.96it/s]\n","[main] 12 [20000]b [240000]tot f=109.48 best[12] elapsed [51 s]\n","\t\t\t@10    @20    @30    @40    @50    @60    @70    @80    @90    @100  \n","cold start\t0.5435 0.6746 0.7456 0.7956 0.8262 0.8460 0.8739 0.8892 0.8977 0.9028\n","updates=260k f=0.0033 f_tot=105.60: 100% 20000/20000 [00:51<00:00, 391.16it/s]\n","[main] 13 [20000]b [260000]tot f=105.60 best[12] elapsed [53 s]\n","\t\t\t@10    @20    @30    @40    @50    @60    @70    @80    @90    @100  \n","cold start\t0.5449 0.6738 0.7443 0.7923 0.8262 0.8455 0.8732 0.8865 0.8961 0.9020\n","updates=280k f=0.0038 f_tot=107.39: 100% 20000/20000 [00:51<00:00, 391.53it/s]\n","[main] 14 [20000]b [280000]tot f=107.39 best[12] elapsed [53 s]\n","\t\t\t@10    @20    @30    @40    @50    @60    @70    @80    @90    @100  \n","cold start\t0.5467 0.6685 0.7356 0.7902 0.8223 0.8420 0.8688 0.8810 0.8918 0.8980\n","updates=300k f=0.0087 f_tot=106.53: 100% 20000/20000 [00:50<00:00, 398.53it/s]\n","[main] 15 [20000]b [300000]tot f=106.53 best[15] elapsed [52 s]\n","\t\t\t@10    @20    @30    @40    @50    @60    @70    @80    @90    @100  \n","cold start\t0.5429 0.6709 0.7443 0.7967 0.8284 0.8505 0.8755 0.8888 0.8982 0.9037\n","updates=304k f=0.0023 f_tot=22.14:  20% 4069/20000 [00:10<00:42, 372.23it/s]\n","\n"]}]},{"cell_type":"markdown","source":["수도권 여행 로그 데이터 결과"],"metadata":{"id":"1bMIY2VK8I04"}},{"cell_type":"markdown","metadata":{"id":"LHLxNu0no8jO"},"source":["## 2023.10.12-11:08\n","- 실행 후 약 2분 40초 후 정지. 코드 상 main.py의 66줄 이후까지 결과 확인됨.\n","- prep eval 부분을 하고 끝나는지 그 전에 마치는지 봐야함\n","\n","## 2023.10.12-11:23\n","- prep eval에서 timer.tic()이후 종료되는 것 같음\n","- 71라인의 init_tf에 문제가 있을 것으로 예상\n","\n","## 2023.10.13-14:13\n","- Colab 기준 코드 실행시 GPU RAM 의 변화량 없음\n","- GPU 설정이 잘 되었는지 확인하기\n","\n","## 2023.10.13-14:44\n","- 일단 main.py의 eval_warm.init_tf에서 실행이 안되므로 해당 부분 코드 print()로 확인\n","\n","## 2023.10.13-14:58\n","- 높은 확률로 Colab의 메모리부족으로 인한 문제인 것으로 추정\n","\n","## 2023.10.13-15:18\n","- DropoutNet이 데이터를 어떻게 불러오는지 파악할 예정\n","- 첫 번째 문제: init_tf에서의 메모리 문제 -> todense 실행 중 종료\n","- V_content_test 데이터가 어디로부터 시작되는지 파악해야 함\n","\n","## 2023.10.13-15:22\n","- V_content_test = item_content\\[self.test_item_ids, :]\n","- item_content 인자: init_tf의 4번째 인자\n","- self.test_item_ids 인자: EvalData 생성자의 2번째 인자로부터 얻어짐\n","- eval_warm = dat\\['eval_warm'] 값임\n","- eval_warm.init_tf()실행하므로 eval_warm은 EvalData 클래스이며 eval_batch_size가 5번째 인자 값으로 들어감(5 번째를 4 번째 인자로 착각해서 찾음...)\n","- 초기 eval_batch_size = 1000으로 설정\n","\n","## 2023.10.13-15:28\n","- 초기 eval_batch_size의 값을 줄여보는 방식으로 코드 실행 예정\n","\n","## 2023.10.13-15:41\n","- user_batch_size, eval_batch_size 각각 200으로 줄였을 때 실패\n","- 각각 값을 32로 초기화하고 재실행\n","- 32도 실패시 2로 설정해보고 진행\n","- 그래도 실패시 data를 불러오고 저장한 값들을 generator 형식으로 변형한 후 진행할 예정\n","\n","## 2023.10.13-15:45\n","- batch_size가 관여하는 코드 가기 전 todense에서 RAM을 12.7GB 찍고 종료됨\n","- 이전에 메모리 관리를 할 방도를 고려해야함\n","\n","## 2023.10.13-15:48\n","- item_content_파일, 확인 요망\n","\n","## 2023.10.13-16:01\n","- Item_content 변수의 원래 파일은 item_features_0based.txt이다.\n","- 해당 파일은 libsvm format의 파일\n","\n","## libsvm format 파일의 형태\n","- DATA_NUM feature_num:value, feature_num2:value ... feature_numN:value\n","- 데이터 번호 이후 여러 feature에 대한 value값들로 구성됨\n","\n","## 2023.10.13-16:14\n","- 현재 진행상황에 대한 결론\n","- DropoutNet 참 좋은 모델인 것은 맞음\n","- 그러나 사용 데이터가 오픈되지 않음\n","- 따라서 관련된 데이터로부터 vector값으로 이미 처리됨\n","- 논문을 읽고 어떻게 vector와 했는지 감이 잡히고 실행 가능하면 해당 모델로 쭉 가도 될 것 같음\n","- but 어떻게 libsvm, 등의 파일의 값을 추출했는지에 대한 설명이 없으면 불가\n","\n","## 2023.10.13-19:47\n","- 논문의 Experiments 부분 읽은 후 CiteULike dataset으로 모델 돌려보기로 결정\n","- CiteULike의 User/Item의 개수가 훨씬 적음(각각 5,551/16,980 개)\n","- Github 설명따라 main_cold_citeu.py 실행, but 오류 발생\n","- 266줄의 pd.read_csv()중 header 값에서 오류\n","```\n","ValueError: Passing negative integer to header is invalid. For no header, use header=None instead\n","```\n","- 불러오는 파일의 헤더 확인 필요\n","\n","## 2023.10.13-19:54\n","```python\n","split_folder = os.path.join(data_path, 'cold')\n","train_file = os.path.join(split_folder, 'train.csv')\n","```\n","- 해당 경로 /eval/cold/train.csv 확인\n","- train.csv는 총 \\{\"A\", \"B\", \"C\"} 3개의 column으로 구성\n","- 각각의 column의 의미 파악 필요\n","\n","## 2023.10.13-20:08\n","- train.csv는 User-Item pair에 대한 matrix\n","\n","## 2023.10.13-20:30~21:17\n","- 기존 train_file 불러오는 코드 수정 후 오류 해결\n","- 이후 test_cold_file 불러오는 코드 오류, 해결\n","- 이후 data.py 124줄의 undefined xrange 변수 오류 발견, range로 변경\n","```\n","AttributeError: module 'tensorflow' has no attribute 'ConfigProto'\n","```\n","- 이후 해당 오류 발견\n","- tf.compat.v1.ConfigProto()코드로 변경\n","```\n","AttributeError: module 'tensorflow' has no attribute 'placeholder'\n","```\n","- 해당 오류:tf1 오류 tf2 되면서 사라짐\n","- tf.compat.v1.placeholder로 변경해 사용 유지\n","- 대부분의 코드 tf2의 model.py 참고해 실행\n","\n","## 2023.10.13-21:49\n","- main_cold_citeu.py 성공적으로 돌아가는 것 확인\n","- 훈련이 잘 마치고도 에러 없는지 확인해야함\n","- 현재 epoch 돌면서 훈련 진행 중\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"u9L5UobluUry"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}